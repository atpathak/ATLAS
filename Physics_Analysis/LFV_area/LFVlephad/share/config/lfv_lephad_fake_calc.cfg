# -*- mode: config -*-
# name of the output file
makeSampleFile.sampleFile:  input/fake_calc.root:samples
# use the following to run over standard nTuples
# run over mc
#makeSampleFile.mcPaths: /eos/atlas/atlascerngroupdisk/phys-higgs/HSG4/LepHad/hsm_lephad/2017-07/mc/nom:NOMINAL
#makeSampleFile.mcPaths: /eos/atlas/user/a/ademaria/Slim_July_Production/mc_nom:NOMINAL
#makeSampleFile.mcPaths: /eos/user/n/ndang/lfv_data/2017-Mar/mc/:NOMINAL
makeSampleFile.mcPaths: /eos/atlas/user/a/ademaria/Slim_July_Production/mc_nom:NOMINAL
#makeSampleFile.mcPaths: /afs/cern.ch/work/n/ndang/private/mc:NOMINAL
# root://eosuser/
makeSampleFile.mcFilenameSuffix: */*.root*
makeSampleFile.mcFilenamePrefix: *
# run over data
#makeSampleFile.dataPaths: /eos/atlas/atlascerngroupdisk/phys-higgs/HSG4/LepHad/hsm_lephad/2017-07/data/nom:NOMINAL
#makeSampleFile.dataPaths:  /eos/user/n/ndang/lfv_data/2017-Jul/data:NOMINAL
makeSampleFile.dataPaths:  /eos/atlas/user/a/ademaria/Slim_July_Production/data:NOMINAL
#makeSampleFile.ddWjets.dataPaths: /eos/atlas/user/a/ademaria/Slim_July_Production/data:NOMINAL
makeSampleFile.dataFilePattern:  *Data*/*.root*
# input cross section files (and map)
makeSampleFile.XsecFiles: XSec/xsecs_lfv.csv
#makeSampleFile.XsecFiles: XSec/xsecs_pmg.txt
makeSampleFile.XsecMap: maps/lfv_lephad.map
makeSampleFile.channelPlaceholder: channel
# where to get the normalization from
makeSampleFile.initializer.verbose: True
makeSampleFile.initializer.useCountHistogram: True
makeSampleFile.initializer.countHistogramName: h_metadata
makeSampleFile.initializer.countHistogramBinNumber: 8
makeSampleFile.initializer.minSamples: 1
makeSampleFile.printSamplesFailed: True
# channels to run over
makeSampleFile.channels: mtau,etau
# energy and luminosity
#makeSampleFile.luminosity: 3.21296
#makeSampleFile.luminosity: 33.24299
makeSampleFile.luminosity: 36.074
#36.45595
makeSampleFile.luminosityUnit: fb
makeSampleFile.energy: 13
makeSampleFile.style: styles/lfv_lephad_tags.txt
makeSampleFile.style1: styles/lfv_lephad_addtags.txt

###
config.Include: definitions/lfv_lephad_aliases.cfg
#runAnalysis.maxEvents: 1
runAnalysis.inputFile:   input/fake_calc.root:samples
runAnalysis.outputFile:  output/fake_calc.root:samples
#runAnalysis.weightSystematicsFile: systematics/weightsystematics
#runAnalysis.kinematicSystematicsFile: systematics/kinematicsystematics
#runAnalysis.fakeSystematicsFile: systematics/fakesystematics
runAnalysis.addObservables: Trigger,ScaleFactor
#runAnalysis.cuts: cuts/lfv_lephad_fake_calc_Sep.def
runAnalysis.cuts: cuts/lfv_lephad_fake_calc.def
runAnalysis.doData: true #false
runAnalysis.channels: mtau
runAnalysis.histograms: definitions/lfv_lephad_fake_calc_histograms.txt

###

calcFakes.inputFile: output/fake_calc_new.root:samples
calcFakes.distributionR: transverseMassLepMET
#calcFakes.distributionUnit: GeV
#original binning if empty
calcFakes.binningR:
#0,500
calcFakes.distributionFF: tauPt
#original binning if empty
calcFakes.binningFF:
calcFakes.prongs: 1Prong,3Prong
calcFakes.triggers: SLT
calcFakes.categories: Preselection,SR0,SR1,SR2,SR3,SRVBF,SRW,SRTop,SRQCD,SRQCD2,SRZtt
#,VBFCB,BOOSTCB,VBFMVA,BOOSTMVA
calcFakes.regions: SR,WCR,QCDCR
#no closure if empty
calcFakes.processes: W,QCD
#W,Z,Top,QCD
calcFakes.year: 2016
#no variation if empty
calcFakes.varyR: 0.5,1.5
calcFakes.outputFileR:  fakefactors_AP/R_fake.root
calcFakes.outputFileFF: fakefactors_AP/FF_fake.root
#calcFakes.outputFileR: output/fake_calc/R_fake.root
#calcFakes.outputFileFF: output/fake_calc/FF_fake.root



#readAnalysis.nfConfig:  normalization/normVBF.txt
readAnalysis.inputFile:  output/fake_calc_2.root:samples
readAnalysis.outputDir:  results/lfv_lephad_fake
readAnalysis.logScale: False
readAnalysis.makePlots: *
readAnalysis.makeCutflows: True
readAnalysis.channels: mtau
readAnalysis.plotter.style.showEventYields: False
#readAnalysis.plotter.style.showOptScan: True
readAnalysis.plotter.labels.process: "H#rightarrow#mu#tau_{had}"
#readAnalysis.histogramProcesses: styles/lfv_lephad_fake_processes.txt
readAnalysis.histogramProcesses: styles/lfv_lephad_processes.txt
readAnalysis.cutflowProcessFiles: styles/lfv_lephad_cutprocesses.txt
readAnalysis.cutflowCutFiles: styles/lfv_lephad_cuts.txt
#readAnalysis.cutprinter.standalone: True
readAnalysis.plotformat: pdf
#readAnalysis.systematics: "systematics/systematics_november.root:systematics>>::somename"
#readAnalysis.plotter.errors.showSys: "somename"
readAnalysis.plotter.labels.atlas: "Work in Progress"
readAnalysis.plotter.labels.atlas.scale: 0.9
readAnalysis.plotter.labels.drawATLAS.scale: 1.21
readAnalysis.plotter.labels.drawInfo: True
readAnalysis.plotter.style.forceRatioLimits: True
readAnalysis.plotter.style.ratioMin: 0.6
readAnalysis.plotter.style.ratioMax: 1.4
#readAnalysis.plotter.labels.totalBkg: "Z MC Fakes"
#readAnalysis.plotter.labels.data: "Z MC"
readAnalysis.plotter.style.legend.textSize: 0.022
readAnalysis.plotter.style.ratio.nYdiv: 4
readAnalysis.plotter.labels.totalBkg: "Bkg"
readAnalysis.plotter.style.showUnderflow: True
readAnalysis.plotter.style.showOverflow: True
readAnalysis.plotter.style.heatmap: True
#readAnalysis.plotter.style.logMinMin: 10
readAnalysis.plotter.style.overrideTotalBkgRequirement: true

#createSystematics.weightSystematicsFile: systematics/plot.systematics
#createSystematics.inputDir: output/fake_november
#createSystematics.nominalFile: nominal.root
#createSystematics.sampleFolder: :samples
#createSystematics.channel: lephad
#createSystematics.cuts: CutVBFCBSR,CutBOOSTCBSR,CutVBFMVASR,CutBOOSTMVASR
#createSystematics.outputDir: systematics
#createSystematics.outputFile: systematics_november.root
#createSystematics.tableName: systematics_table_november
